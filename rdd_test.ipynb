{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model and infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_yml = r'e:\\PaddlePaddle\\PaddleDetection\\configs\\ppyoloe\\ppyoloe_plus_crn_l_custom.yml'\n",
    "best_model_path = r'e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_l_custom\\best_model.pdparams'\n",
    "inference_model = r\"e:\\PaddlePaddle\\PaddleDetection\\output_inference\\ppyoloe_plus_crn_l_custom\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export model for paddle2onnx\n",
    "!python tools/export_model.py -c $control_yml -o weights=$best_model_path trt=True exclude_nms=True TestReader.inputs_def.image_shape=[3,480,480]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for inference\n",
    "!python tools/export_model.py -c $control_yml -o weights=$best_model_path trt=True TestReader.inputs_def.image_shape=[3,480,480]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate images for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "image_path = r'dataset\\road_disease_voc\\images'\n",
    "test_path = r'dataset\\road_disease_voc\\test_images'\n",
    "if os.path.exists(test_path):\n",
    "    shutil.rmtree(test_path)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "imgs = glob.glob(os.path.join(image_path, '**', '*.jpg'), recursive=True)\n",
    "infer_imgs = np.random.choice(imgs, 10)\n",
    "for img in infer_imgs:\n",
    "    img_name = os.path.basename(img)\n",
    "    src_path = img\n",
    "    dst_path = os.path.join(test_path, img_name)\n",
    "    shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python tools/infer.py -c $control_yml -o weights=$best_model_path --infer_dir=$test_path --output_dir=results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paddle Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python deploy/python/infer.py --model_dir=$inference_model --image_dir=$test_path --device=GPU --run_mode=trt_fp16 --output_dir=results_trt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxsim\n",
    "import numpy as np\n",
    "import onnx_graphsurgeon as gs\n",
    "from onnx import shape_inference\n",
    "from collections import OrderedDict\n",
    "\n",
    "# 注意修改\n",
    "########################################################\n",
    "INPUT_PATH = './onnx_model/ppyoloe_plus_crn_l_custom_std.onnx'\n",
    "WEIGHTS_TYPE = \"l\"\n",
    "SAVE_PATH = './onnx_nms_model/ppyoloe_plus_crn_l_custom_std_nms.onnx'\n",
    "CLASS_NUM = 4\n",
    "SCORE_THRESHOLD = 0.25\n",
    "IOU_THRESHOLD = 0.45\n",
    "########################################################\n",
    "\n",
    "if(WEIGHTS_TYPE==\"s\"):\n",
    "    Mul_name = 'Mul_78'\n",
    "elif(WEIGHTS_TYPE==\"m\"):\n",
    "    Mul_name = 'Mul_100'\n",
    "elif(WEIGHTS_TYPE==\"l\"):\n",
    "    Mul_name = 'Mul_244'\n",
    "elif(WEIGHTS_TYPE==\"x\"):\n",
    "    Mul_name = 'Mul_144'\n",
    "\n",
    "gs_graph = gs.import_onnx(onnx.load(INPUT_PATH))\n",
    "# fold constants\n",
    "gs_graph.fold_constants()\n",
    "gs_graph.cleanup().toposort()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modify NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "Mul = [node for node in gs_graph.nodes if node.name=='p2o.Mul.244'][0]\n",
    "Concat_14 = [node for node in gs_graph.nodes if node.name=='p2o.Concat.28'][0]\n",
    "\n",
    "scores = gs.Variable(name='scores',shape=[1,4725,CLASS_NUM],dtype=np.float32)\n",
    "Transpose = gs.Node(name='lastTranspose',op='Transpose',\n",
    "                   inputs=[Concat_14.outputs[0]],\n",
    "                   outputs=[scores],\n",
    "                   attrs=OrderedDict(perm=[0,2,1]))\n",
    "gs_graph.nodes.append(Transpose)\n",
    "\n",
    "Mul.outputs[0].name = 'boxes'\n",
    "gs_graph.inputs = [gs_graph.inputs[0]]\n",
    "gs_graph.outputs = [Mul.outputs[0],scores]\n",
    "gs_graph.outputs[0].dtype=np.float32\n",
    "gs_graph.outputs[1].dtype=np.float32\n",
    "\n",
    "gs_graph.cleanup().toposort()\n",
    "onnx_graph = shape_inference.infer_shapes(gs.export_onnx(gs_graph))\n",
    "onnx_graph, check = onnxsim.simplify(onnx_graph)\n",
    "\n",
    "gs_graph = gs.import_onnx(onnx_graph)\n",
    "op_inputs = gs_graph.outputs\n",
    "op = \"EfficientNMS_TRT\"\n",
    "attrs = {\n",
    "    \"plugin_version\": \"1\",\n",
    "    \"background_class\": -1,\n",
    "    \"max_output_boxes\": 100,\n",
    "    \"score_threshold\": SCORE_THRESHOLD,\n",
    "    \"iou_threshold\": IOU_THRESHOLD,\n",
    "    \"score_activation\": False,\n",
    "    \"box_coding\": 0,\n",
    "}\n",
    "\n",
    "output_num_detections = gs.Variable(\n",
    "    name=\"num_dets\",\n",
    "    dtype=np.int32,\n",
    "    shape=[1, 1],\n",
    ")\n",
    "output_boxes = gs.Variable(\n",
    "    name=\"det_boxes\",\n",
    "    dtype=np.float32,\n",
    "    shape=[1, 100, 4],\n",
    ")\n",
    "output_scores = gs.Variable(\n",
    "    name=\"det_scores\",\n",
    "    dtype=np.float32,\n",
    "    shape=[1, 100],\n",
    ")\n",
    "output_labels = gs.Variable(\n",
    "    name=\"det_classes\",\n",
    "    dtype=np.int32,\n",
    "    shape=[1, 100],\n",
    ")\n",
    "op_outputs = [\n",
    "    output_num_detections, output_boxes, output_scores, output_labels\n",
    "]\n",
    "\n",
    "TRT = gs.Node(op=op,name=\"batched_nms\",inputs=op_inputs,outputs=op_outputs,attrs=attrs)\n",
    "gs_graph.nodes.append(TRT)\n",
    "gs_graph.outputs = op_outputs\n",
    "gs_graph.cleanup().toposort()\n",
    "\n",
    "onnx.save(gs.export_onnx(gs_graph),SAVE_PATH)\n",
    "print(\"finished\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get engine and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "class BaseEngine(object):\n",
    "    def __init__(self, engine_path, imgsz=(480,480)):\n",
    "        self.imgsz = imgsz\n",
    "        logger = trt.Logger(trt.Logger.WARNING)\n",
    "        runtime = trt.Runtime(logger)\n",
    "        trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "        with open(engine_path, \"rb\") as f:\n",
    "            serialized_engine = f.read()\n",
    "        engine = runtime.deserialize_cuda_engine(serialized_engine)\n",
    "        self.context = engine.create_execution_context()\n",
    "        self.inputs, self.outputs, self.bindings = [], [], []\n",
    "        self.stream = cuda.Stream()\n",
    "        for binding in engine:\n",
    "            size = trt.volume(engine.get_binding_shape(binding))\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            self.bindings.append(int(device_mem))\n",
    "            if engine.binding_is_input(binding):\n",
    "                self.inputs.append({'host': host_mem, 'device': device_mem})\n",
    "            else:\n",
    "                self.outputs.append({'host': host_mem, 'device': device_mem})        \n",
    "\n",
    "    def predict(self, img,threshold):\n",
    "        self.img = self.preprocess(img)\n",
    "        self.inputs[0]['host'] = np.ravel(self.img)\n",
    "        # transfer data to the gpu\n",
    "        for inp in self.inputs:\n",
    "            cuda.memcpy_htod_async(inp['device'], inp['host'], self.stream)\n",
    "        # run inference\n",
    "        self.context.execute_async_v2(\n",
    "            bindings=self.bindings,\n",
    "            stream_handle=self.stream.handle)\n",
    "        # fetch outputs from gpu\n",
    "        for out in self.outputs:\n",
    "            cuda.memcpy_dtoh_async(out['host'], out['device'], self.stream)\n",
    "        # synchronize stream\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        data = [out['host'] for out in self.outputs]\n",
    "        results = self.postprocess(data,threshold)\n",
    "        return results\n",
    "\n",
    "    def letterbox(self,im,color=(114, 114, 114), auto=False, scaleup=True, stride=32):\n",
    "        # Resize and pad image while meeting stride-multiple constraints\n",
    "        shape = im.shape[:2]  # current shape [height, width]\n",
    "        new_shape = self.imgsz\n",
    "        if isinstance(new_shape, int):\n",
    "            new_shape = (new_shape, new_shape)\n",
    "        # Scale ratio (new / old)\n",
    "        self.r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "        if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "            self.r = min(self.r, 1.0)\n",
    "        # Compute padding\n",
    "        new_unpad = int(round(shape[1] * self.r)), int(round(shape[0] * self.r))\n",
    "        self.dw, self.dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "        if auto:  # minimum rectangle\n",
    "            self.dw, self.dh = np.mod(self.dw, stride), np.mod(self.dh, stride)  # wh padding\n",
    "        self.dw /= 2  # divide padding into 2 sides\n",
    "        self.dh /= 2\n",
    "        if shape[::-1] != new_unpad:  # resize\n",
    "            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "        top, bottom = int(round(self.dh - 0.1)), int(round(self.dh + 0.1))\n",
    "        left, right = int(round(self.dw - 0.1)), int(round(self.dw + 0.1))\n",
    "        self.img = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "        return self.img,self.r,self.dw,self.dh\n",
    "\n",
    "    def preprocess(self,image):\n",
    "        self.img,self.r,self.dw,self.dh = self.letterbox(image)\n",
    "        self.img = cv2.cvtColor(self.img,cv2.COLOR_BGR2RGB)\n",
    "        self.img = self.img.astype(np.float32)\n",
    "        self.img = self.img / 255.\n",
    "        self.img -= np.array([0.485, 0.456, 0.406])[None, None, :]\n",
    "        self.img /= np.array([0.229, 0.224, 0.225])[None, None, :]\n",
    "        self.img = self.img.transpose((2, 0, 1))\n",
    "        self.img = np.expand_dims(self.img,0)\n",
    "        return self.img\n",
    "\n",
    "    def postprocess(self,pred,threshold):\n",
    "        new_bboxes = []\n",
    "        num =int(pred[0][0])\n",
    "        bboxes = pred[1].reshape(-1,4)\n",
    "        scores = pred[2]\n",
    "        clas = pred[3]\n",
    "        for i in range(num):\n",
    "            if(scores[i] < threshold):\n",
    "                continue\n",
    "            xmin = (bboxes[i][0] - self.dw)/self.r\n",
    "            ymin = (bboxes[i][1] - self.dh)/self.r\n",
    "            xmax = (bboxes[i][2] - self.dw)/self.r\n",
    "            ymax = (bboxes[i][3] - self.dh)/self.r\n",
    "            new_bboxes.append([clas[i],scores[i],xmin,ymin,xmax,ymax])\n",
    "        return new_bboxes\n",
    "\n",
    "\n",
    "def visualize(img,bbox_array):\n",
    "    for temp in bbox_array:\n",
    "        xmin = int(temp[2])\n",
    "        ymin = int(temp[3])\n",
    "        xmax = int(temp[4])\n",
    "        ymax = int(temp[5])\n",
    "        clas = int(temp[0])\n",
    "        score = temp[1]\n",
    "\n",
    "        \"\"\"\n",
    "        LineCrack\n",
    "        AligatorCrack\n",
    "        Repair\n",
    "        Pothole\n",
    "\n",
    "        \"\"\"\n",
    "        clas = {0:\"LineCrack\",1:\"AligatorCrack\",2:\"Repair\",3:\"Pothole\"}[clas]\n",
    "\n",
    "        cv2.rectangle(img,(xmin,ymin),(xmax,ymax), (105, 237, 249), 2)\n",
    "        img = cv2.putText(img, \"class:\"+str(clas)+\" \"+str(round(score,2)), (xmin,int(ymin)+16), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (105, 237, 249), 1)\n",
    "    return img\n",
    "\n",
    "trt_engine = BaseEngine(\"onnx_nms_model/ppyoloe_plus_crn_l_custom_std_nms.engine\")\n",
    "img1 = cv2.imread(r\"dataset\\rdd\\test_images\\China_Drone_000621.jpg\")\n",
    "results = trt_engine.predict(img1,threshold=0.5)\n",
    "img = visualize(img1,results)\n",
    "\n",
    "cv2.imwrite(\"results_trt/China_Drone_000621_pycuda.jpg\",img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit trt_engine.predict(img1,threshold=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## formal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"results_trt\"):\n",
    "    shutil.rmtree(\"results_trt\")\n",
    "os.makedirs(\"results_trt\", exist_ok=True)\n",
    "trt_engine = BaseEngine(\"onnx_nms_model/ppyoloe_plus_crn_l_custom_std_nms.engine\")\n",
    "for img in glob.glob(f\"{test_path}/*.jpg\"):\n",
    "    img1 = cv2.imread(img)\n",
    "    results = trt_engine.predict(img1,threshold=0.5)\n",
    "    img1 = visualize(img1,results)\n",
    "    cv2.imwrite(\"results_trt/\"+os.path.basename(img),img1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
