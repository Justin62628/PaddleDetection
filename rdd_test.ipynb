{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export model and eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_yml = r'e:\\PaddlePaddle\\PaddleDetection\\configs\\ppyoloe\\ppyoloe_plus_crn_m_custom.yml'\n",
    "# best_model_path = r'e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_l_custom_disease\\69.pdparams'\n",
    "best_model_path = r'e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\178.pdparams'\n",
    "# best_model_path = r'e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\best_model.pdparams'\n",
    "inference_model = r\"e:\\PaddlePaddle\\PaddleDetection\\output_inference\\ppyoloe_plus_crn_m_custom\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/12 15:59:10] ppdet.utils.checkpoint INFO: Finish loading model weights: e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\178.pdparams\n",
      "[05/12 15:59:11] ppdet.engine INFO: Export inference config file to output_inference\\ppyoloe_plus_crn_m_custom\\infer_cfg.yml\n",
      "[05/12 15:59:20] ppdet.engine INFO: Export model and saved in output_inference\\ppyoloe_plus_crn_m_custom\n"
     ]
    }
   ],
   "source": [
    "# export model for trt\n",
    "!python tools/export_model.py -c $control_yml -o weights=$best_model_path trt=True exclude_nms=True TestReader.inputs_def.image_shape=[3,512,512] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/12 15:59:59] ppdet.utils.checkpoint INFO: Finish loading model weights: e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\178.pdparams\n",
      "[05/12 16:00:00] ppdet.engine INFO: Export inference config file to output_inference\\ppyoloe_plus_crn_m_custom\\infer_cfg.yml\n",
      "[05/12 16:00:07] ppdet.engine INFO: Export model and saved in output_inference\\ppyoloe_plus_crn_m_custom\n"
     ]
    }
   ],
   "source": [
    "# for inference\n",
    "!python tools/export_model.py -c $control_yml -o weights=$best_model_path TestReader.inputs_def.image_shape=[3,512,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/12 15:56:56] ppdet.utils.checkpoint INFO: Finish loading model weights: e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\178.pdparams\n",
      "[05/12 15:56:59] ppdet.engine INFO: Eval iter: 0\n",
      "[05/12 15:57:03] ppdet.metrics.metrics INFO: Accumulating evaluatation results...\n",
      "[05/12 15:57:04] ppdet.metrics.map_utils INFO: Per-category of VOC AP: \n",
      "+-----------+-------+---------------+-------+----------+-------+\n",
      "| category  | AP    | category      | AP    | category | AP    |\n",
      "+-----------+-------+---------------+-------+----------+-------+\n",
      "| LineCrack | 0.558 | AligatorCrack | 0.311 | Repair   | 0.477 |\n",
      "| Pothole   | 0.729 | None          | None  | None     | None  |\n",
      "+-----------+-------+---------------+-------+----------+-------+\n",
      "[05/12 15:57:04] ppdet.metrics.map_utils INFO: per-category PR curve has output to voc_pr_curve folder.\n",
      "[05/12 15:57:04] ppdet.metrics.metrics INFO: mAP(0.50, 11point) = 51.87%\n",
      "[05/12 15:57:04] ppdet.engine INFO: Total sample number: 168, average FPS: 23.273503629301842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0512 15:56:53.906421  7952 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 11.6\n",
      "W0512 15:56:53.906421  7952 gpu_resources.cc:91] device: 0, cuDNN Version: 8.8.\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "!python tools/eval.py -c $control_yml -o weights=$best_model_path TestReader.inputs_def.image_shape=[3,512,512] --classwise --match_metric iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/12 15:58:22] ppdet.utils.checkpoint INFO: Finish loading model weights: e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\best_model.pdparams\n",
      "[05/12 15:58:25] ppdet.engine INFO: Eval iter: 0\n",
      "[05/12 15:58:29] ppdet.metrics.metrics INFO: Accumulating evaluatation results...\n",
      "[05/12 15:58:30] ppdet.metrics.map_utils INFO: Per-category of VOC AP: \n",
      "+-----------+-------+---------------+-------+----------+-------+\n",
      "| category  | AP    | category      | AP    | category | AP    |\n",
      "+-----------+-------+---------------+-------+----------+-------+\n",
      "| LineCrack | 0.639 | AligatorCrack | 0.341 | Repair   | 0.558 |\n",
      "| Pothole   | 0.784 | None          | None  | None     | None  |\n",
      "+-----------+-------+---------------+-------+----------+-------+\n",
      "[05/12 15:58:30] ppdet.metrics.map_utils INFO: per-category PR curve has output to voc_pr_curve folder.\n",
      "[05/12 15:58:30] ppdet.metrics.metrics INFO: mAP(0.50, 11point) = 58.04%\n",
      "[05/12 15:58:30] ppdet.engine INFO: Total sample number: 168, average FPS: 22.876860891767084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0512 15:58:19.954591  9920 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 11.6\n",
      "W0512 15:58:19.954591  9920 gpu_resources.cc:91] device: 0, cuDNN Version: 8.8.\n"
     ]
    }
   ],
   "source": [
    "# eval\n",
    "!python tools/eval.py -c $control_yml -o weights=e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\best_model.pdparams TestReader.inputs_def.image_shape=[3,512,512] --classwise --match_metric iou"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate images for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "image_path = r'dataset\\disease\\images'\n",
    "test_path = r'dataset\\disease\\test_images'\n",
    "if os.path.exists(test_path):\n",
    "    shutil.rmtree(test_path)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "imgs = glob.glob(os.path.join(image_path, '**', '*.jpg'), recursive=True)\n",
    "infer_imgs = np.random.choice(imgs, 10)\n",
    "for img in infer_imgs:\n",
    "    img_name = os.path.basename(img)\n",
    "    src_path = img\n",
    "    dst_path = os.path.join(test_path, img_name)\n",
    "    shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/12 16:04:56] ppdet.utils.checkpoint INFO: Finish loading model weights: e:\\PaddlePaddle\\PaddleDetection\\output\\ppyoloe_plus_crn_m_custom\\178.pdparams\n",
      "[05/12 16:04:56] train INFO: Found 10 inference images in total.\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\109d0d78e7294d1010ead9e87f7096d5.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\2a92b51749b90f12b768781d2213c530.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\165f3d4735f58631f6b576e955c4d4a6.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\2f16f050329b3bf0364dc8836e3035cc.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\7f76b0385fe59a6a5bce536bf60e92fb.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\af8bdd916639e80d06d31411d46f7167.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\fcc271696d86a360f4176593501d5f78.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\59bba3b22e6bdae61f388b1e5bfe59cc.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\abe26f6bf9d07535a00c20daf54b1a2d.jpg\n",
      "[05/12 16:04:58] ppdet.engine INFO: Detection bbox results save in results\\23cc6bd291bbca4d89172cfa11fb6961.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0512 16:04:54.323982 10352 gpu_resources.cc:61] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.7, Runtime API Version: 11.6\n",
      "W0512 16:04:54.323982 10352 gpu_resources.cc:91] device: 0, cuDNN Version: 8.8.\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      " 10%|█         | 1/10 [00:01<00:14,  1.64s/it]\n",
      " 40%|████      | 4/10 [00:01<00:02,  2.94it/s]\n",
      " 70%|███████   | 7/10 [00:01<00:00,  5.65it/s]\n",
      "100%|██████████| 10/10 [00:01<00:00,  5.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# infer with dynamic graphs\n",
    "import os\n",
    "if os.path.exists(\"results\"):\n",
    "    shutil.rmtree(\"results\")\n",
    "!python tools/infer.py -c $control_yml -o weights=$best_model_path --infer_dir=$test_path --output_dir=results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------  Running Arguments -----------\n",
      "action_file: None\n",
      "batch_size: 1\n",
      "camera_id: -1\n",
      "combine_method: nms\n",
      "cpu_threads: 1\n",
      "device: CPU\n",
      "enable_mkldnn: False\n",
      "enable_mkldnn_bfloat16: False\n",
      "image_dir: dataset\\disease\\test_images\n",
      "image_file: None\n",
      "match_metric: ios\n",
      "match_threshold: 0.6\n",
      "model_dir: e:\\PaddlePaddle\\PaddleDetection\\output_inference\\ppyoloe_plus_crn_m_custom\n",
      "output_dir: results\n",
      "overlap_ratio: [0.25, 0.25]\n",
      "random_pad: False\n",
      "reid_batch_size: 50\n",
      "reid_model_dir: None\n",
      "run_benchmark: False\n",
      "run_mode: paddle\n",
      "save_images: True\n",
      "save_mot_txt_per_img: False\n",
      "save_mot_txts: False\n",
      "save_results: False\n",
      "scaled: False\n",
      "slice_infer: False\n",
      "slice_size: [640, 640]\n",
      "threshold: 0.5\n",
      "tracker_config: None\n",
      "trt_calib_mode: False\n",
      "trt_max_shape: 1280\n",
      "trt_min_shape: 1\n",
      "trt_opt_shape: 640\n",
      "use_coco_category: False\n",
      "use_dark: True\n",
      "use_gpu: False\n",
      "video_file: None\n",
      "window_size: 50\n",
      "------------------------------------------\n",
      "-----------  Model Configuration -----------\n",
      "Model Arch: YOLO\n",
      "Transform Order: \n",
      "--transform op: Resize\n",
      "--transform op: NormalizeImage\n",
      "--transform op: Permute\n",
      "--------------------------------------------\n",
      "Found 10 inference images in total.\n",
      "save result to: results\\5ff2bcdfdc78921f1214a11577463fb7.jpg\n",
      "Test iter 0\n",
      "class_id:0, confidence:0.6760, left_top:[526.93,251.83],right_bottom:[634.17,781.61]\n",
      "class_id:0, confidence:0.5245, left_top:[560.95,258.31],right_bottom:[621.58,791.79]\n",
      "save result to: results\\4c3f8b5ea1b15f8ac4dc4f78437c83df.jpg\n",
      "Test iter 1\n",
      "class_id:3, confidence:0.8407, left_top:[182.72,13.77],right_bottom:[239.82,84.10]\n",
      "class_id:3, confidence:0.8064, left_top:[112.72,22.52],right_bottom:[147.45,59.31]\n",
      "save result to: results\\ab046fe40d96644ace037aafcd2b7149.jpg\n",
      "Test iter 2\n",
      "class_id:3, confidence:0.9129, left_top:[448.44,253.81],right_bottom:[668.41,426.31]\n",
      "save result to: results\\207c7ec1b25c4f495fd609fb118ddcf7.jpg\n",
      "Test iter 3\n",
      "class_id:3, confidence:0.9329, left_top:[1321.16,1869.94],right_bottom:[3627.09,4183.47]\n",
      "save result to: results\\e5eca8ed755a34a9c5e5166a0f694594.jpg\n",
      "Test iter 4\n",
      "class_id:0, confidence:0.9464, left_top:[1000.51,198.98],right_bottom:[2192.95,2024.99]\n",
      "save result to: results\\ec2bcfe887eb03e305c89d41dbedca3d.jpg\n",
      "Test iter 5\n",
      "class_id:3, confidence:0.9071, left_top:[592.95,1157.94],right_bottom:[874.03,1286.32]\n",
      "class_id:3, confidence:0.8300, left_top:[1071.12,1199.69],right_bottom:[1337.90,1345.25]\n",
      "save result to: results\\96af8408bf1585b4292218a3fb7dcbcc.jpg\n",
      "Test iter 6\n",
      "class_id:3, confidence:0.9633, left_top:[616.44,359.53],right_bottom:[925.65,604.77]\n",
      "class_id:3, confidence:0.7384, left_top:[1054.70,576.44],right_bottom:[1180.87,728.42]\n",
      "save result to: results\\d92637a8ed357a1cdf51749d5ce452c9.jpg\n",
      "Test iter 7\n",
      "class_id:3, confidence:0.5786, left_top:[372.94,286.08],right_bottom:[539.11,347.52]\n",
      "save result to: results\\3e8a19e6ee47d08d672d4135e8289f69.jpg\n",
      "Test iter 8\n",
      "class_id:0, confidence:0.8920, left_top:[1354.70,420.09],right_bottom:[2088.06,2257.46]\n",
      "save result to: results\\6a1eabd1e5acdddb2adab61e5c0afe5c.jpg\n",
      "Test iter 9\n",
      "------------------ Inference Time Info ----------------------\n",
      "total_time(ms): 9494.1, img_num: 10\n",
      "average latency time(ms): 949.41, QPS: 1.053286\n",
      "preprocess_time(ms): 83.20, inference_time(ms): 866.30, postprocess_time(ms): 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n",
      "e:\\PaddlePaddle\\PaddleDetection\\deploy\\python\\visualize.py:162: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.\n",
      "  tw, th = draw.textsize(text)\n"
     ]
    }
   ],
   "source": [
    "# infer with dynamic graphs\n",
    "\n",
    "# !python deploy/python/infer.py --model_dir=$inference_model --image_dir=$test_path --device=GPU --run_mode=trt_fp16 --output_dir=results_trt\n",
    "if os.path.exists(\"results\"):\n",
    "    shutil.rmtree(\"results\")\n",
    "!python deploy/python/infer.py --model_dir=$inference_model --image_dir=$test_path --device=CPU --output_dir=results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31;40m2023-05-12 16:06:27 [WARNING]\t[Deprecated] The flag `--input_shape_dict` is deprecated, if you need to modify the input shape of PaddlePaddle model, please refer to this tool https://github.com/jiangjiajun/PaddleUtils/tree/main/paddle \u001b[0m\n",
      "[Paddle2ONNX] Start to parse PaddlePaddle model...\n",
      "[Paddle2ONNX] Model file path: output_inference/ppyoloe_plus_crn_m_custom_std_trt\\model.pdmodel\n",
      "[Paddle2ONNX] Paramters file path: output_inference/ppyoloe_plus_crn_m_custom_std_trt\\model.pdiparams\n",
      "[Paddle2ONNX] Start to parsing Paddle model...\n",
      "[Paddle2ONNX] [nearest_interp_v2: nearest_interp_v2_0.tmp_0] Requires the minimal opset version of 11.\n",
      "[Paddle2ONNX] [nearest_interp_v2: nearest_interp_v2_1.tmp_0] Requires the minimal opset version of 11.\n",
      "[Paddle2ONNX] Due to the operator: nearest_interp_v2, requires opset_version >= 11.\n",
      "[Paddle2ONNX] Opset version will change to 11 from 9\n",
      "[Paddle2ONNX] Use opset_version = 11 for ONNX export.\n",
      "[Paddle2ONNX] PaddlePaddle model is exported as ONNX format now.\n",
      "2023-05-12 16:06:29 [INFO]\t===============Make PaddlePaddle Better!================\n",
      "2023-05-12 16:06:29 [INFO]\tA little survey: https://iwenjuan.baidu.com/?code=r8hu2s\n"
     ]
    }
   ],
   "source": [
    "# Export \n",
    "!paddle2onnx --model_dir output_inference/ppyoloe_plus_crn_m_custom_std_trt --model_filename model.pdmodel --params_filename model.pdiparams --save_file onnx_model/ppyoloe_plus_crn_m_custom_std_trt.onnx --input_shape_dict \"{'image':[1, 3, 512, 512], 'scale_factor': [1, 2]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxsim\n",
    "import numpy as np\n",
    "import onnx_graphsurgeon as gs\n",
    "from onnx import shape_inference\n",
    "from collections import OrderedDict\n",
    "import os\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Using ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import cv2\n",
    "images = glob.glob(os.path.join(test_path, '**', '*.jpg'), recursive=True)\n",
    "model = ort.InferenceSession(\"onnx_model/ppyoloe_plus_crn_m_custom_std.onnx\", providers=[\"CUDAExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import onnxruntime as rt\n",
    "import cv2\n",
    "import numpy as np\n",
    "class BaseOnnxInfer(object):\n",
    "    def __init__(self, onnx_path, imgsz=(480,480)):\n",
    "        self.imgsz = imgsz\n",
    "        self.sess = ort.InferenceSession(onnx_path, providers=[\"CUDAExecutionProvider\"])\n",
    "        \n",
    "    def predict(self, img,threshold):\n",
    "        self.img = self.preprocess(img)\n",
    "        data = self.sess.run([\"multiclass_nms3_0.tmp_0\",\"multiclass_nms3_0.tmp_2\"], {'image': self.img, 'scale_factor': np.array([self.scale_factor]).astype('float32')})\n",
    "        results = self.postprocess(data, threshold)\n",
    "        return results\n",
    "\n",
    "    def letterbox(self,im,color=(114, 114, 114), auto=False, scaleup=True, stride=32):\n",
    "        # Resize and pad image while meeting stride-multiple constraints\n",
    "        shape = im.shape[:2]  # current shape [height, width]\n",
    "        new_shape = self.imgsz\n",
    "        if isinstance(new_shape, int):\n",
    "            new_shape = (new_shape, new_shape)\n",
    "        # Scale ratio (new / old)\n",
    "        self.scale_factor = new_shape[0] / shape[0], new_shape[1] / shape[1]\n",
    "        self.img = cv2.resize(im, new_shape)  # add border\n",
    "        return self.img\n",
    "\n",
    "    def preprocess(self,image):\n",
    "        self.img = self.letterbox(image)\n",
    "        self.img = cv2.cvtColor(self.img,cv2.COLOR_BGR2RGB)\n",
    "        self.img = self.img.astype(np.float32)\n",
    "        self.img = self.img / 255.\n",
    "        self.img -= np.array([0.485, 0.456, 0.406])[None, None, :]\n",
    "        self.img /= np.array([0.229, 0.224, 0.225])[None, None, :]\n",
    "        self.img = self.img.transpose((2, 0, 1))\n",
    "        self.img = np.expand_dims(self.img,0)\n",
    "        return self.img\n",
    "\n",
    "    def postprocess(self,pred,threshold):\n",
    "        new_bboxes = []\n",
    "        for _pred in pred[0]:\n",
    "            clas = _pred[0]\n",
    "            score = _pred[1]\n",
    "            if(score < threshold):\n",
    "                continue\n",
    "            bboxes = _pred[2:6]\n",
    "            # xmin = (bboxes[0] - self.dw)/self.r\n",
    "            # ymin = (bboxes[1] - self.dh)/self.r\n",
    "            # xmax = (bboxes[2] - self.dw)/self.r\n",
    "            # ymax = (bboxes[3] - self.dh)/self.r\n",
    "            xmin, ymin, xmax, ymax = bboxes\n",
    "            new_bboxes.append([clas, score, xmin,ymin,xmax,ymax])\n",
    "        return new_bboxes\n",
    "\n",
    "\n",
    "def visualize(img,bbox_array):\n",
    "    cc_map = {0:(\"LineCrack\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              1:(\"AligatorCrack\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              2:(\"Repair\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              3:(\"Pothole\", (255,np.random.randint(0,255),np.random.randint(0,255)))}\n",
    "    for temp in bbox_array:\n",
    "        xmin = int(temp[2])\n",
    "        ymin = int(temp[3])\n",
    "        xmax = int(temp[4])\n",
    "        ymax = int(temp[5])\n",
    "        clas = int(temp[0])\n",
    "        score = temp[1]\n",
    "\n",
    "        \"\"\"\n",
    "        LineCrack\n",
    "        AligatorCrack\n",
    "        Repair\n",
    "        Pothole\n",
    "\n",
    "        \"\"\"\n",
    "        clas, color = cc_map[clas]\n",
    "        cv2.rectangle(img,(xmin,ymin),(xmax,ymax), color, 2)\n",
    "        img = cv2.putText(img, \"class:\"+str(clas)+\" \"+str(round(score,2)), (xmin,int(ymin)+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return img\n",
    "\n",
    "sess = BaseOnnxInfer(\"onnx_model/ppyoloe_plus_crn_m_custom_std.onnx\", imgsz=(512,512))\n",
    "img1 = cv2.imread(r\"dataset\\rdd\\test_images\\China_Drone_000621.jpg\")\n",
    "results = sess.predict(img1,threshold=0.5)\n",
    "img = visualize(img1,results)\n",
    "\n",
    "cv2.imwrite(\"results/result.png\", img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpeedTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.6 ms ± 545 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit sess.predict(img1,threshold=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"results_onnx\"):\n",
    "    shutil.rmtree(\"results_onnx\")\n",
    "os.makedirs(\"results_onnx\", exist_ok=True)\n",
    "trt_engine = BaseOnnxInfer(\"onnx_model/ppyoloe_plus_crn_m_custom_std.onnx\", imgsz=(512,512))\n",
    "for img in glob.glob(f\"{test_path}/*.jpg\"):\n",
    "    img1 = cv2.imread(img)\n",
    "    results = trt_engine.predict(img1,threshold=0.4)\n",
    "    img1 = visualize(img1,results)\n",
    "    cv2.imwrite(\"results_onnx/\"+os.path.basename(img),img1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# Place EfficientNMS for TensorRT\n",
    "# 注意修改\n",
    "########################################################\n",
    "INPUT_PATH = './onnx_model/ppyoloe_plus_crn_m_custom_std_trt.onnx'\n",
    "WEIGHTS_TYPE = \"l\"\n",
    "SAVE_PATH = './onnx_nms_model/ppyoloe_plus_crn_m_custom_std_trt_nms.onnx'\n",
    "CLASS_NUM = 4\n",
    "SCORE_THRESHOLD = 0.25\n",
    "IOU_THRESHOLD = 0.45\n",
    "########################################################\n",
    "\n",
    "gs_graph = gs.import_onnx(onnx.load(INPUT_PATH))\n",
    "# fold constants\n",
    "gs_graph.fold_constants()\n",
    "gs_graph.cleanup().toposort()\n",
    "\n",
    "\n",
    "Mul = [node for node in gs_graph.nodes if node.name=='p2o.Mul.200'][0]\n",
    "Concat_14 = [node for node in gs_graph.nodes if node.name=='p2o.Concat.28'][0]\n",
    "Mul_linear = 5376\n",
    "\n",
    "scores = gs.Variable(name='scores',shape=[1,Mul_linear,CLASS_NUM],dtype=np.float32)\n",
    "Transpose = gs.Node(name='lastTranspose',op='Transpose',\n",
    "                   inputs=[Concat_14.outputs[0]],\n",
    "                   outputs=[scores],\n",
    "                   attrs=OrderedDict(perm=[0,2,1]))\n",
    "gs_graph.nodes.append(Transpose)\n",
    "\n",
    "Mul.outputs[0].name = 'boxes'\n",
    "gs_graph.inputs = [gs_graph.inputs[0]]\n",
    "gs_graph.outputs = [Mul.outputs[0],scores]\n",
    "gs_graph.outputs[0].dtype=np.float32\n",
    "gs_graph.outputs[1].dtype=np.float32\n",
    "\n",
    "gs_graph.cleanup().toposort()\n",
    "onnx_graph = shape_inference.infer_shapes(gs.export_onnx(gs_graph))\n",
    "onnx_graph, check = onnxsim.simplify(onnx_graph)\n",
    "\n",
    "gs_graph = gs.import_onnx(onnx_graph)\n",
    "op_inputs = gs_graph.outputs\n",
    "op = \"EfficientNMS_TRT\"\n",
    "attrs = {\n",
    "    \"plugin_version\": \"1\",\n",
    "    \"background_class\": -1,\n",
    "    \"max_output_boxes\": 100,\n",
    "    \"score_threshold\": SCORE_THRESHOLD,\n",
    "    \"iou_threshold\": IOU_THRESHOLD,\n",
    "    \"score_activation\": False,\n",
    "    \"box_coding\": 0,\n",
    "}\n",
    "\n",
    "output_num_detections = gs.Variable(\n",
    "    name=\"num_dets\",\n",
    "    dtype=np.int32,\n",
    "    shape=[1, 1],\n",
    ")\n",
    "output_boxes = gs.Variable(\n",
    "    name=\"det_boxes\",\n",
    "    dtype=np.float32,\n",
    "    shape=[1, 100, 4],\n",
    ")\n",
    "output_scores = gs.Variable(\n",
    "    name=\"det_scores\",\n",
    "    dtype=np.float32,\n",
    "    shape=[1, 100],\n",
    ")\n",
    "output_labels = gs.Variable(\n",
    "    name=\"det_classes\",\n",
    "    dtype=np.int32,\n",
    "    shape=[1, 100],\n",
    ")\n",
    "op_outputs = [\n",
    "    output_num_detections, output_boxes, output_scores, output_labels\n",
    "]\n",
    "\n",
    "TRT = gs.Node(op=op,name=\"batched_nms\",inputs=op_inputs,outputs=op_outputs,attrs=attrs)\n",
    "gs_graph.nodes.append(TRT)\n",
    "gs_graph.outputs = op_outputs\n",
    "gs_graph.cleanup().toposort()\n",
    "\n",
    "onnx.save(gs.export_onnx(gs_graph),SAVE_PATH)\n",
    "print(\"finished\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorRT\n",
    "```bash\n",
    "trtexec.exe --onnx=e:\\PaddlePaddle\\PaddleDetection\\onnx_nms_model\\ppyoloe_plus_crn_m_custom_std_trt_nms.onnx --saveEngine=e:\\PaddlePaddle\\PaddleDetection\\onnx_nms_model\\ppyoloe_plus_crn_m_custom_std_trt_nms.engine --fp16\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get engine and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8232\\98667936.py:21: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  size = trt.volume(engine.get_binding_shape(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8232\\98667936.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8232\\98667936.py:26: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if engine.binding_is_input(binding):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "class BaseEngine(object):\n",
    "    def __init__(self, engine_path, imgsz=(480,480)):\n",
    "        self.imgsz = imgsz\n",
    "        logger = trt.Logger(trt.Logger.WARNING)\n",
    "        runtime = trt.Runtime(logger)\n",
    "        trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "        with open(engine_path, \"rb\") as f:\n",
    "            serialized_engine = f.read()\n",
    "        engine = runtime.deserialize_cuda_engine(serialized_engine)\n",
    "        self.context = engine.create_execution_context()\n",
    "        self.inputs, self.outputs, self.bindings = [], [], []\n",
    "        self.stream = cuda.Stream()\n",
    "        for binding in engine:\n",
    "            size = trt.volume(engine.get_binding_shape(binding))\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            self.bindings.append(int(device_mem))\n",
    "            if engine.binding_is_input(binding):\n",
    "                self.inputs.append({'host': host_mem, 'device': device_mem})\n",
    "            else:\n",
    "                self.outputs.append({'host': host_mem, 'device': device_mem})        \n",
    "\n",
    "    def predict(self, img,threshold):\n",
    "        self.img = self.preprocess(img)\n",
    "        self.inputs[0]['host'] = np.ravel(self.img)\n",
    "        # transfer data to the gpu\n",
    "        for inp in self.inputs:\n",
    "            cuda.memcpy_htod_async(inp['device'], inp['host'], self.stream)\n",
    "        # run inference\n",
    "        self.context.execute_async_v2(\n",
    "            bindings=self.bindings,\n",
    "            stream_handle=self.stream.handle)\n",
    "        # fetch outputs from gpu\n",
    "        for out in self.outputs:\n",
    "            cuda.memcpy_dtoh_async(out['host'], out['device'], self.stream)\n",
    "        # synchronize stream\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        data = [out['host'] for out in self.outputs]\n",
    "        results = self.postprocess(data,threshold)\n",
    "        return results\n",
    "\n",
    "    def letterbox(self,im,color=(114, 114, 114), auto=False, scaleup=True, stride=32):\n",
    "        # Resize and pad image while meeting stride-multiple constraints\n",
    "        shape = im.shape[:2]  # current shape [height, width]\n",
    "        new_shape = self.imgsz\n",
    "        if isinstance(new_shape, int):\n",
    "            new_shape = (new_shape, new_shape)\n",
    "        # Scale ratio (new / old)\n",
    "        self.r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "        if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "            self.r = min(self.r, 1.0)\n",
    "        # Compute padding\n",
    "        new_unpad = int(round(shape[1] * self.r)), int(round(shape[0] * self.r))\n",
    "        self.dw, self.dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "        if auto:  # minimum rectangle\n",
    "            self.dw, self.dh = np.mod(self.dw, stride), np.mod(self.dh, stride)  # wh padding\n",
    "        self.dw /= 2  # divide padding into 2 sides\n",
    "        self.dh /= 2\n",
    "        if shape[::-1] != new_unpad:  # resize\n",
    "            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "        top, bottom = int(round(self.dh - 0.1)), int(round(self.dh + 0.1))\n",
    "        left, right = int(round(self.dw - 0.1)), int(round(self.dw + 0.1))\n",
    "        self.img = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "        return self.img,self.r,self.dw,self.dh\n",
    "\n",
    "    def preprocess(self,image):\n",
    "        self.img,self.r,self.dw,self.dh = self.letterbox(image)\n",
    "        self.img = cv2.cvtColor(self.img,cv2.COLOR_BGR2RGB)\n",
    "        self.img = self.img.astype(np.float32)\n",
    "        self.img = self.img / 255.\n",
    "        self.img -= np.array([0.485, 0.456, 0.406])[None, None, :]\n",
    "        self.img /= np.array([0.229, 0.224, 0.225])[None, None, :]\n",
    "        self.img = self.img.transpose((2, 0, 1))\n",
    "        self.img = np.expand_dims(self.img,0)\n",
    "        return self.img\n",
    "\n",
    "    def postprocess(self,pred,threshold):\n",
    "        new_bboxes = []\n",
    "        num =int(pred[0][0])\n",
    "        bboxes = pred[1].reshape(-1,4)\n",
    "        scores = pred[2]\n",
    "        clas = pred[3]\n",
    "        for i in range(num):\n",
    "            if(scores[i] < threshold):\n",
    "                continue\n",
    "            xmin = (bboxes[i][0] - self.dw)/self.r\n",
    "            ymin = (bboxes[i][1] - self.dh)/self.r\n",
    "            xmax = (bboxes[i][2] - self.dw)/self.r\n",
    "            ymax = (bboxes[i][3] - self.dh)/self.r\n",
    "            new_bboxes.append([clas[i],scores[i],xmin,ymin,xmax,ymax])\n",
    "        return new_bboxes\n",
    "\n",
    "\n",
    "def visualize(img,bbox_array):\n",
    "    cc_map = {0:(\"LineCrack\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              1:(\"AligatorCrack\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              2:(\"Repair\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              3:(\"Pothole\", (255,np.random.randint(0,255),np.random.randint(0,255)))}\n",
    "    for temp in bbox_array:\n",
    "        xmin = int(temp[2])\n",
    "        ymin = int(temp[3])\n",
    "        xmax = int(temp[4])\n",
    "        ymax = int(temp[5])\n",
    "        clas = int(temp[0])\n",
    "        score = temp[1]\n",
    "\n",
    "        \"\"\"\n",
    "        LineCrack\n",
    "        AligatorCrack\n",
    "        Repair\n",
    "        Pothole\n",
    "\n",
    "        \"\"\"\n",
    "        clas, color = cc_map[clas]\n",
    "        cv2.rectangle(img,(xmin,ymin),(xmax,ymax), color, 2)\n",
    "        img = cv2.putText(img, \"class:\"+str(clas)+\" \"+str(round(score,2)), (xmin,int(ymin)+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return img\n",
    "\n",
    "trt_engine = BaseEngine(\"onnx_nms_model/ppyoloe_plus_crn_m_custom_std_trt_nms.engine\", imgsz=(512,512))\n",
    "img1 = cv2.imread(r\"dataset\\rdd\\test_images\\China_Drone_000621.jpg\")\n",
    "results = trt_engine.predict(img1,threshold=0.5)\n",
    "img = visualize(img1,results)\n",
    "\n",
    "cv2.imwrite(\"results_trt/China_Drone_000621.jpg\",img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speed Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7 ms ± 382 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trt_engine.predict(img1,threshold=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## formal inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8232\\98667936.py:21: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  size = trt.volume(engine.get_binding_shape(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8232\\98667936.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_8232\\98667936.py:26: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if engine.binding_is_input(binding):\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(\"results_trt\"):\n",
    "    shutil.rmtree(\"results_trt\")\n",
    "os.makedirs(\"results_trt\", exist_ok=True)\n",
    "trt_engine = BaseEngine(\"onnx_nms_model/ppyoloe_plus_crn_l_custom_disease_std_v2_nms.engine\", imgsz=(512,512))\n",
    "for img in glob.glob(f\"{test_path}/*.jpg\"):\n",
    "    img1 = cv2.imread(img)\n",
    "    results = trt_engine.predict(img1,threshold=0.4)\n",
    "    img1 = visualize(img1,results)\n",
    "    cv2.imwrite(\"results_trt/\"+os.path.basename(img),img1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
