input_list: ['image', 'scale_factor', 'im_shape']  # necessary for ssdlite; for picodet, only 'image', 'scale_factor'
model_dir: output_inference/ssdlite_mobilenet_v3_small_custom
model_filename: model.pdmodel
params_filename: model.pdiparams
save_dir: output/analysis_results
metric: VOC
map_type: 11point
num_classes: 4
plot_hist: True
get_target_quant_model: False
target_metric: None

PTQ:
  quantizable_op_type: ["conv2d", "depthwise_conv2d"]
  weight_quantize_type: 'abs_max'
  activation_quantize_type: 'moving_average_abs_max'
  is_full_quantize: False
  batch_size: 10
  batch_nums: 10

# Datset configuration

EvalDataset:
  !VOCDataSet
    dataset_dir: dataset/alum/
    anno_path: val.txt
    label_list: label_list.txt
    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']


# Small Dataset to accelerate analysis
# If not exist, delete the dict of FastEvalDataset
# FastEvalDataset:
#   !COCODataSet
#     image_dir: val2017
#     anno_path: annotations/small_instances_val2017.json
#     dataset_dir: /dataset/coco/


# enabled only when QAT
eval_height: &eval_height 320
eval_width: &eval_width 320
eval_size: &eval_size [*eval_height, *eval_width]

worker_num: 1
bufsize: 3

EvalReader:
  sample_transforms:
  - Decode: {}
  - Resize: {interp: 2, target_size: *eval_size, keep_ratio: False}
  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
  - Permute: {}
  batch_transforms:
  - PadBatch: {pad_to_stride: 32}
  batch_size: 1
  shuffle: false

