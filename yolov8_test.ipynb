{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "class_names = ['LineCrack', 'AligatorCrack', 'Repair', 'Pothole']\n",
    "\n",
    "# Create a list of colors for each class where each color is a tuple of 3 integer values\n",
    "rng = np.random.default_rng(3)\n",
    "colors = rng.uniform(0, 255, size=(len(class_names), 3))\n",
    "\n",
    "\n",
    "def nms(boxes, scores, iou_threshold):\n",
    "    # Sort by score\n",
    "    sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    keep_boxes = []\n",
    "    while sorted_indices.size > 0:\n",
    "        # Pick the last box\n",
    "        box_id = sorted_indices[0]\n",
    "        keep_boxes.append(box_id)\n",
    "\n",
    "        # Compute IoU of the picked box with the rest\n",
    "        ious = compute_iou(boxes[box_id, :], boxes[sorted_indices[1:], :])\n",
    "\n",
    "        # Remove boxes with IoU over the threshold\n",
    "        keep_indices = np.where(ious < iou_threshold)[0]\n",
    "\n",
    "        # print(keep_indices.shape, sorted_indices.shape)\n",
    "        sorted_indices = sorted_indices[keep_indices + 1]\n",
    "\n",
    "    return keep_boxes\n",
    "\n",
    "\n",
    "def compute_iou(box, boxes):\n",
    "    # Compute xmin, ymin, xmax, ymax for both boxes\n",
    "    xmin = np.maximum(box[0], boxes[:, 0])\n",
    "    ymin = np.maximum(box[1], boxes[:, 1])\n",
    "    xmax = np.minimum(box[2], boxes[:, 2])\n",
    "    ymax = np.minimum(box[3], boxes[:, 3])\n",
    "\n",
    "    # Compute intersection area\n",
    "    intersection_area = np.maximum(0, xmax - xmin) * np.maximum(0, ymax - ymin)\n",
    "\n",
    "    # Compute union area\n",
    "    box_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "    boxes_area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    union_area = box_area + boxes_area - intersection_area\n",
    "\n",
    "    # Compute IoU\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n",
    "def xywh2xyxy(x):\n",
    "    # Convert bounding box (x, y, w, h) to bounding box (x1, y1, x2, y2)\n",
    "    y = np.copy(x)\n",
    "    y[..., 0] = x[..., 0] - x[..., 2] / 2\n",
    "    y[..., 1] = x[..., 1] - x[..., 3] / 2\n",
    "    y[..., 2] = x[..., 0] + x[..., 2] / 2\n",
    "    y[..., 3] = x[..., 1] + x[..., 3] / 2\n",
    "    return y\n",
    "\n",
    "\n",
    "def draw_detections(image, boxes, scores, class_ids, mask_alpha=0.3):\n",
    "    mask_img = image.copy()\n",
    "    det_img = image.copy()\n",
    "\n",
    "    img_height, img_width = image.shape[:2]\n",
    "    size = min([img_height, img_width]) * 0.0006\n",
    "    text_thickness = int(min([img_height, img_width]) * 0.001)\n",
    "\n",
    "    # Draw bounding boxes and labels of detections\n",
    "    for box, score, class_id in zip(boxes, scores, class_ids):\n",
    "        color = colors[class_id]\n",
    "\n",
    "        x1, y1, x2, y2 = box.astype(int)\n",
    "\n",
    "        # Draw rectangle\n",
    "        cv2.rectangle(det_img, (x1, y1), (x2, y2), color, 2)\n",
    "\n",
    "        # Draw fill rectangle in mask image\n",
    "        cv2.rectangle(mask_img, (x1, y1), (x2, y2), color, -1)\n",
    "\n",
    "        label = class_names[class_id]\n",
    "        caption = f'{label} {int(score * 100)}%'\n",
    "        (tw, th), _ = cv2.getTextSize(text=caption, fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                      fontScale=size, thickness=text_thickness)\n",
    "        th = int(th * 1.2)\n",
    "\n",
    "        cv2.rectangle(det_img, (x1, y1),\n",
    "                      (x1 + tw, y1 - th), color, -1)\n",
    "        cv2.rectangle(mask_img, (x1, y1),\n",
    "                      (x1 + tw, y1 - th), color, -1)\n",
    "        cv2.putText(det_img, caption, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "        cv2.putText(mask_img, caption, (x1, y1),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, size, (255, 255, 255), text_thickness, cv2.LINE_AA)\n",
    "\n",
    "    return cv2.addWeighted(mask_img, mask_alpha, det_img, 1 - mask_alpha, 0)\n",
    "\n",
    "\n",
    "def draw_comparison(img1, img2, name1, name2, fontsize=2.6, text_thickness=3):\n",
    "    (tw, th), _ = cv2.getTextSize(text=name1, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                  fontScale=fontsize, thickness=text_thickness)\n",
    "    x1 = img1.shape[1] // 3\n",
    "    y1 = th\n",
    "    offset = th // 5\n",
    "    cv2.rectangle(img1, (x1 - offset * 2, y1 + offset),\n",
    "                  (x1 + tw + offset * 2, y1 - th - offset), (0, 115, 255), -1)\n",
    "    cv2.putText(img1, name1,\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, fontsize,\n",
    "                (255, 255, 255), text_thickness)\n",
    "\n",
    "\n",
    "    (tw, th), _ = cv2.getTextSize(text=name2, fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                                  fontScale=fontsize, thickness=text_thickness)\n",
    "    x1 = img2.shape[1] // 3\n",
    "    y1 = th\n",
    "    offset = th // 5\n",
    "    cv2.rectangle(img2, (x1 - offset * 2, y1 + offset),\n",
    "                  (x1 + tw + offset * 2, y1 - th - offset), (94, 23, 235), -1)\n",
    "\n",
    "    cv2.putText(img2, name2,\n",
    "                (x1, y1),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, fontsize,\n",
    "                (255, 255, 255), text_thickness)\n",
    "\n",
    "    combined_img = cv2.hconcat([img1, img2])\n",
    "    if combined_img.shape[1] > 3840:\n",
    "        combined_img = cv2.resize(combined_img, (3840, 2160))\n",
    "\n",
    "    return combined_img\n",
    "\n",
    "class YOLOv8:\n",
    "\n",
    "    def __init__(self, path, conf_thres=0.7, iou_thres=0.5):\n",
    "        self.conf_threshold = conf_thres\n",
    "        self.iou_threshold = iou_thres\n",
    "\n",
    "        # Initialize model\n",
    "        self.initialize_model(path)\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return self.detect_objects(image)\n",
    "\n",
    "    def initialize_model(self, path):\n",
    "        self.session = onnxruntime.InferenceSession(path,\n",
    "                                                    providers=['CUDAExecutionProvider',\n",
    "                                                               'CPUExecutionProvider'])\n",
    "        # Get model info\n",
    "        self.get_input_details()\n",
    "        self.get_output_details()\n",
    "\n",
    "\n",
    "    def detect_objects(self, image):\n",
    "        input_tensor = self.prepare_input(image)\n",
    "\n",
    "        # Perform inference on the image\n",
    "        outputs = self.inference(input_tensor)\n",
    "\n",
    "        self.boxes, self.scores, self.class_ids = self.process_output(outputs)\n",
    "\n",
    "        return self.boxes, self.scores, self.class_ids\n",
    "\n",
    "    def prepare_input(self, image):\n",
    "        self.img_height, self.img_width = image.shape[:2]\n",
    "\n",
    "        input_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize input image\n",
    "        input_img = cv2.resize(input_img, (self.input_width, self.input_height))\n",
    "\n",
    "        # Scale input pixel values to 0 to 1\n",
    "        input_img = input_img / 255.0\n",
    "        input_img = input_img.transpose(2, 0, 1)\n",
    "        input_tensor = input_img[np.newaxis, :, :, :].astype(np.float32)\n",
    "\n",
    "        return input_tensor\n",
    "\n",
    "\n",
    "    def inference(self, input_tensor):\n",
    "        start = time.perf_counter()\n",
    "        outputs = self.session.run(self.output_names, {self.input_names[0]: input_tensor})\n",
    "\n",
    "        # print(f\"Inference time: {(time.perf_counter() - start)*1000:.2f} ms\")\n",
    "        return outputs\n",
    "\n",
    "    def process_output(self, output):\n",
    "        predictions = np.squeeze(output[0]).T\n",
    "\n",
    "        # Filter out object confidence scores below threshold\n",
    "        scores = np.max(predictions[:, 4:], axis=1)\n",
    "        predictions = predictions[scores > self.conf_threshold, :]\n",
    "        scores = scores[scores > self.conf_threshold]\n",
    "\n",
    "        if len(scores) == 0:\n",
    "            return [], [], []\n",
    "\n",
    "        # Get the class with the highest confidence\n",
    "        class_ids = np.argmax(predictions[:, 4:], axis=1)\n",
    "\n",
    "        # Get bounding boxes for each object\n",
    "        boxes = self.extract_boxes(predictions)\n",
    "\n",
    "        # Apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "        indices = nms(boxes, scores, self.iou_threshold)\n",
    "\n",
    "        return boxes[indices], scores[indices], class_ids[indices]\n",
    "\n",
    "    def extract_boxes(self, predictions):\n",
    "        # Extract boxes from predictions\n",
    "        boxes = predictions[:, :4]\n",
    "\n",
    "        # Scale boxes to original image dimensions\n",
    "        boxes = self.rescale_boxes(boxes)\n",
    "\n",
    "        # Convert boxes to xyxy format\n",
    "        boxes = xywh2xyxy(boxes)\n",
    "\n",
    "        return boxes\n",
    "\n",
    "    def rescale_boxes(self, boxes):\n",
    "\n",
    "        # Rescale boxes to original image dimensions\n",
    "        input_shape = np.array([self.input_width, self.input_height, self.input_width, self.input_height])\n",
    "        boxes = np.divide(boxes, input_shape, dtype=np.float32)\n",
    "        boxes *= np.array([self.img_width, self.img_height, self.img_width, self.img_height])\n",
    "        return boxes\n",
    "\n",
    "    def draw_detections(self, image, draw_scores=True, mask_alpha=0.4):\n",
    "\n",
    "        return draw_detections(image, self.boxes, self.scores,\n",
    "                               self.class_ids, mask_alpha)\n",
    "\n",
    "    def get_input_details(self):\n",
    "        model_inputs = self.session.get_inputs()\n",
    "        self.input_names = [model_inputs[i].name for i in range(len(model_inputs))]\n",
    "\n",
    "        self.input_shape = model_inputs[0].shape\n",
    "        self.input_height = self.input_shape[2]\n",
    "        self.input_width = self.input_shape[3]\n",
    "\n",
    "    def get_output_details(self):\n",
    "        model_outputs = self.session.get_outputs()\n",
    "        self.output_names = [model_outputs[i].name for i in range(len(model_outputs))]\n",
    "\n",
    "\n",
    "model_path = r\"E:\\PaddlePaddle\\PaddleDetection\\onnx_model\\yolov8_std.onnx\"\n",
    "\n",
    "detector = YOLOv8(model_path, conf_thres=0.3, iou_thres=0.5)\n",
    "\n",
    "img = cv2.imread(r\"dataset\\rdd\\test_images\\China_Drone_000621.jpg\")\n",
    "\n",
    "# Detect Objects\n",
    "detector(img)\n",
    "\n",
    "# Draw detections\n",
    "combined_img = detector.draw_detections(img)\n",
    "cv2.imwrite(\"results/result_yolo.jpg\",combined_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "image_path = r'dataset\\disease\\images'\n",
    "test_path = r'dataset\\disease\\test_images'\n",
    "if os.path.exists(test_path):\n",
    "    shutil.rmtree(test_path)\n",
    "os.makedirs(test_path, exist_ok=True)\n",
    "imgs = glob.glob(os.path.join(image_path, '**', '*.jpg'), recursive=True)\n",
    "infer_imgs = np.random.choice(imgs, 10)\n",
    "for img in infer_imgs:\n",
    "    img_name = os.path.basename(img)\n",
    "    src_path = img\n",
    "    dst_path = os.path.join(test_path, img_name)\n",
    "    shutil.copy(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "path = \"results_yolo\"\n",
    "if os.path.exists(f\"{path}\"):\n",
    "    shutil.rmtree(f\"{path}\")\n",
    "os.makedirs(f\"{path}\", exist_ok=True)\n",
    "\n",
    "model_path = r\"E:\\PaddlePaddle\\PaddleDetection\\onnx_model\\yolov8_std.onnx\"\n",
    "\n",
    "detector = YOLOv8(model_path, conf_thres=0.3, iou_thres=0.5)\n",
    "for img in glob.glob(f\"{test_path}/*.jpg\"):\n",
    "    img1 = cv2.imread(img)\n",
    "    detector(img1)\n",
    "    combined_img = detector.draw_detections(img1)\n",
    "    cv2.imwrite(f\"{path}/\"+os.path.basename(img),combined_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRT\n",
    "```bash\n",
    "trtexec.exe --onnx=E:\\PaddlePaddle\\PaddleDetection\\onnx_model\\yolov8_std_trt.onnx --saveEngine=e:\\PaddlePaddle\\PaddleDetection\\onnx_nms_model\\yolov8_std_trt_nms.engine --fp16 \n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_508\\965655182.py:21: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  size = trt.volume(engine.get_binding_shape(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_508\\965655182.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_508\\965655182.py:26: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if engine.binding_is_input(binding):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorrt as trt\n",
    "import pycuda.autoinit\n",
    "import pycuda.driver as cuda\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "class BaseEngine(object):\n",
    "    def __init__(self, engine_path, imgsz=(480,480)):\n",
    "        self.imgsz = imgsz\n",
    "        logger = trt.Logger(trt.Logger.WARNING)\n",
    "        runtime = trt.Runtime(logger)\n",
    "        trt.init_libnvinfer_plugins(logger, namespace=\"\")\n",
    "        with open(engine_path, \"rb\") as f:\n",
    "            serialized_engine = f.read()\n",
    "        engine = runtime.deserialize_cuda_engine(serialized_engine)\n",
    "        self.context = engine.create_execution_context()\n",
    "        self.inputs, self.outputs, self.bindings = [], [], []\n",
    "        self.stream = cuda.Stream()\n",
    "        for binding in engine:\n",
    "            size = trt.volume(engine.get_binding_shape(binding))\n",
    "            dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
    "            host_mem = cuda.pagelocked_empty(size, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            self.bindings.append(int(device_mem))\n",
    "            if engine.binding_is_input(binding):\n",
    "                self.inputs.append({'host': host_mem, 'device': device_mem})\n",
    "            else:\n",
    "                self.outputs.append({'host': host_mem, 'device': device_mem})        \n",
    "\n",
    "    def predict(self, img,threshold):\n",
    "        self.img = self.preprocess(img)\n",
    "        self.inputs[0]['host'] = np.ravel(self.img)\n",
    "        # transfer data to the gpu\n",
    "        for inp in self.inputs:\n",
    "            cuda.memcpy_htod_async(inp['device'], inp['host'], self.stream)\n",
    "        # run inference\n",
    "        self.context.execute_async_v2(\n",
    "            bindings=self.bindings,\n",
    "            stream_handle=self.stream.handle)\n",
    "        # fetch outputs from gpu\n",
    "        for out in self.outputs:\n",
    "            cuda.memcpy_dtoh_async(out['host'], out['device'], self.stream)\n",
    "        # synchronize stream\n",
    "        self.stream.synchronize()\n",
    "\n",
    "        data = [out['host'] for out in self.outputs]\n",
    "        results = self.postprocess(data,threshold)\n",
    "        return results\n",
    "\n",
    "    def letterbox(self,im,color=(114, 114, 114), auto=False, scaleup=True, stride=32):\n",
    "        # Resize and pad image while meeting stride-multiple constraints\n",
    "        shape = im.shape[:2]  # current shape [height, width]\n",
    "        new_shape = self.imgsz\n",
    "        if isinstance(new_shape, int):\n",
    "            new_shape = (new_shape, new_shape)\n",
    "        # Scale ratio (new / old)\n",
    "        self.r = min(new_shape[0] / shape[0], new_shape[1] / shape[1])\n",
    "        if not scaleup:  # only scale down, do not scale up (for better val mAP)\n",
    "            self.r = min(self.r, 1.0)\n",
    "        # Compute padding\n",
    "        new_unpad = int(round(shape[1] * self.r)), int(round(shape[0] * self.r))\n",
    "        self.dw, self.dh = new_shape[1] - new_unpad[0], new_shape[0] - new_unpad[1]  # wh padding\n",
    "        if auto:  # minimum rectangle\n",
    "            self.dw, self.dh = np.mod(self.dw, stride), np.mod(self.dh, stride)  # wh padding\n",
    "        self.dw /= 2  # divide padding into 2 sides\n",
    "        self.dh /= 2\n",
    "        if shape[::-1] != new_unpad:  # resize\n",
    "            im = cv2.resize(im, new_unpad, interpolation=cv2.INTER_LINEAR)\n",
    "        top, bottom = int(round(self.dh - 0.1)), int(round(self.dh + 0.1))\n",
    "        left, right = int(round(self.dw - 0.1)), int(round(self.dw + 0.1))\n",
    "        self.img = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT, value=color)  # add border\n",
    "        return self.img,self.r,self.dw,self.dh\n",
    "\n",
    "    def preprocess(self,image):\n",
    "        self.img,self.r,self.dw,self.dh = self.letterbox(image)\n",
    "        self.img = cv2.cvtColor(self.img,cv2.COLOR_BGR2RGB)\n",
    "        self.img = self.img.astype(np.float32)\n",
    "        self.img = self.img / 255.\n",
    "        # self.img -= np.array([0.485, 0.456, 0.406])[None, None, :]\n",
    "        # self.img /= np.array([0.229, 0.224, 0.225])[None, None, :]\n",
    "        self.img = self.img.transpose((2, 0, 1))\n",
    "        self.img = np.expand_dims(self.img,0)\n",
    "        return self.img\n",
    "\n",
    "    def postprocess(self,pred,threshold):\n",
    "        new_bboxes = []\n",
    "        num =int(pred[0][0])\n",
    "        bboxes = pred[1].reshape(-1,4)\n",
    "        scores = pred[2]\n",
    "        clas = pred[3]\n",
    "        for i in range(num):\n",
    "            if(scores[i] < threshold):\n",
    "                continue\n",
    "            xmin = (bboxes[i][0] - self.dw)/self.r\n",
    "            ymin = (bboxes[i][1] - self.dh)/self.r\n",
    "            xmax = (bboxes[i][2] - self.dw)/self.r\n",
    "            ymax = (bboxes[i][3] - self.dh)/self.r\n",
    "            new_bboxes.append([clas[i],scores[i],xmin,ymin,xmax,ymax])\n",
    "        return new_bboxes\n",
    "\n",
    "\n",
    "def visualize(img,bbox_array):\n",
    "    cc_map = {0:(\"LineCrack\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              1:(\"AligatorCrack\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              2:(\"Repair\", (255,np.random.randint(0,255),np.random.randint(0,255))),\n",
    "              3:(\"Pothole\", (255,np.random.randint(0,255),np.random.randint(0,255)))}\n",
    "    for temp in bbox_array:\n",
    "        xmin = int(temp[2])\n",
    "        ymin = int(temp[3])\n",
    "        xmax = int(temp[4])\n",
    "        ymax = int(temp[5])\n",
    "        clas = int(temp[0])\n",
    "        score = temp[1]\n",
    "\n",
    "        \"\"\"\n",
    "        LineCrack\n",
    "        AligatorCrack\n",
    "        Repair\n",
    "        Pothole\n",
    "\n",
    "        \"\"\"\n",
    "        clas, color = cc_map[clas]\n",
    "        cv2.rectangle(img,(xmin,ymin),(xmax,ymax), color, 2)\n",
    "        img = cv2.putText(img, \"class:\"+str(clas)+\" \"+str(round(score,2)), (xmin,int(ymin)+20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 1)\n",
    "    return img\n",
    "\n",
    "trt_path = \"onnx_nms_model/yolov8_std_trt_nms.engine\"\n",
    "trt_engine = BaseEngine(trt_path, imgsz=(640, 640))\n",
    "img1 = cv2.imread(r\"dataset\\rdd\\test_images\\China_Drone_000621.jpg\")\n",
    "results = trt_engine.predict(img1,threshold=0.3)\n",
    "img = visualize(img1,results)\n",
    "\n",
    "cv2.imwrite(\"results_trt/yolov8_trt.jpg\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.3 ms ± 108 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit trt_engine.predict(img1,threshold=0.5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_508\\965655182.py:21: DeprecationWarning: Use get_tensor_shape instead.\n",
      "  size = trt.volume(engine.get_binding_shape(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_508\\965655182.py:22: DeprecationWarning: Use get_tensor_dtype instead.\n",
      "  dtype = trt.nptype(engine.get_binding_dtype(binding))\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_508\\965655182.py:26: DeprecationWarning: Use get_tensor_mode instead.\n",
      "  if engine.binding_is_input(binding):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"results_trt\"\n",
    "if os.path.exists(path):\n",
    "    shutil.rmtree(path)\n",
    "os.makedirs(path, exist_ok=True)\n",
    "trt_engine = BaseEngine(trt_path, imgsz=(640,640))\n",
    "for img in glob.glob(f\"{test_path}/*.jpg\"):\n",
    "    img1 = cv2.imread(img)\n",
    "    results = trt_engine.predict(img1,threshold=0.1)\n",
    "    img1 = visualize(img1,results)\n",
    "    cv2.imwrite(f\"{path}/\"+os.path.basename(img),img1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
