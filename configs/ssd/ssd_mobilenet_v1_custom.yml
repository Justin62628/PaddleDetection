_BASE_: [
  './ssd_mobilenet_v1_300_120e_voc.yml'
]

snapshot_epoch: 1
weights: ../output/ssd_mobilenet_v1_custom/model_final

# metric: COCO
metric: VOC

num_classes: 4

# TrainDataset:
#   !COCODataSet
#     image_dir: images
#     anno_path: annotations/train.json
#     dataset_dir: dataset/alum/
#     data_fields: ['image', 'gt_bbox', 'gt_class', 'is_crowd']

# EvalDataset:
#   !COCODataSet
#     image_dir: images
#     anno_path: annotations/valid.json
#     dataset_dir: dataset/alum/

# TestDataset:
#   !ImageFolder
#     anno_path: annotations/valid.json # also support txt (like VOC's label_list.txt)
#     dataset_dir: dataset/alum/ # if set, anno_path will be 'dataset_dir/anno_path'

TrainDataset:
  !VOCDataSet
    dataset_dir: dataset/alum/
    anno_path: train.txt
    label_list: label_list.txt
    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']


EvalDataset:
  !VOCDataSet
    dataset_dir: dataset/alum/
    anno_path: val.txt
    label_list: label_list.txt
    data_fields: ['image', 'gt_bbox', 'gt_class', 'difficult']

TestDataset:
  !ImageFolder
    anno_path: dataset/alum/label_list.txt

bufsize: 3
worker_num: 1

# enabled only when QAT
#eval_height: &eval_height 320
#eval_width: &eval_width 320
#eval_size: &eval_size [*eval_height, *eval_width]
#
#EvalReader:
#  sample_transforms:
#  - Decode: {}
#  - Resize: {interp: 2, target_size: *eval_size, keep_ratio: False}
#  - NormalizeImage: {is_scale: true, mean: [0.485,0.456,0.406], std: [0.229, 0.224,0.225]}
#  - Permute: {}
#  batch_transforms:
#  - PadBatch: {pad_to_stride: 32}
#  batch_size: 1
#  shuffle: false
